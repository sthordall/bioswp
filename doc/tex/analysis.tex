\section{Analysis}
This section will analyze the potential for capturing biometrics on the
\textit{Apple Watch}. The analysis will cover both the hardware and
software, i.e.\ which sensors are included in the watch and how they are 
utilized by the provided frameworks. The sensors will also be evaluated 
on their usefulness for biometric identification. Finally the analysis 
should result in a selection of sensors found appropriate for the prototype.

\subsection{Sensors}
The \textit{Apple Watch} includes a multitude of sensors \cite{Ap16}, 
which are used mainly for usability, activity, fitness and health tracking, but
they are also used for some security functionalities, such as using the heart 
rate sensor, to ensure the owner who unlocked the watch, has not removed the 
watch since authorization occurred.

\subsubsection{Heart rate sensor}
The integrated heart rate sensor uses the technology
\textit{photoplethysmography}. Which functions by using green LED's to
illuminate the veins in the wrist and photodiodes to detect the amount of blood
flowing in said veins. This allows the watch to detect the wearers heart rate
\cite{watchheartrate}.
The quality of measurements rely on the wearers fit of the watch, but when
fitted correctly heart rate data is provided through Apple's \textit{HealthKit}
framework. The heart rate data can be fetched through an instance of
\texttt{HKHealthStore}, and can both be fetched as a stream through a
\texttt{WorkoutSession} and retroactively through queries to the
\texttt{HKHealthStore} \cite{healthkitfw}.
Heart rate data for biometric identification has been explored by other vendors
than Apple \cite{nymiwhitepaper}, but this has been done with different sensors
and raw sensor data. It has been found possible with raw sensor data to identify
individuals from photoplethysmography signals, like the ones obtained from the
Apple Watch sensor \cite{kavsaoglu2013a}. A photoplethysmography sensor
therefore seems like a potential biometric characteristic capture device.


\subsubsection{Accelerometer \& Gyroscope}
Both an accelerometer and a gyroscope are located in the watch, and these are
used for features like activity tracking and rotation detection for screen
auto on/off. Raw data is accessible from both sensors through the
\textit{CoreMotion} framework, from \texttt{CMAccelerometerData} and
\texttt{CMGyroData} accordingly \cite{coremotionfw}. The accelerometer allows
for 3-axis movement tracking, and the gyroscope detects rotation. These in
combination allow for precise movement tracking, but are limited to track the
movement of the wrist. This has been used for activity tracking and pedometer 
in many smart devices, but one might need to investigate the precision of this
before using it for identification. 
Experiments on identifying individuals from motion data has been tested, and
one approach could be gait recognition. Gait recognition allows for
identification from how the subject walks, and research points towards this
being possible from similar sensors within smartphones \cite{7181946}. 

\subsubsection{Microphone}
The watch contains a microphone, used for voice commands and speakerphone. The
microphone can be accessed and used for recordings by the usage
\texttt{AudioRecorderController} spawned with the function
\texttt{presentAudioRecorderControllerWithOutputUrl}. 

%Speech and voice recognition is a field which has benefited immensely from 
%machine learning techniques, such as deep neural networks, over the past few 
%years \cite{6296526}. Speaker recognition is therefore achievable, but is 
%difficult to run on small smart devices, such as the Apple Watch, due to the 
%powerful computations and machine learning techniques required. Nearly all 
%available libraries and software needs to run on powerful servers, with neural
%nets already trained. 
%Furthermore most of the existing software found focuses on \textit{what} the 
%subject says, and not \textit{who} the subject is.

\subsubsection{NFC}
The potential of an NFC chip in the watch seems promising for access control, as
it could allow for interaction with third-party devices, i.e.\ NFC readers. This
could be utilized for doors which rely on NFC key cards, where the watch could
function as a secure device containing the NFC key cards. 
Unfortunately this is simply not possible, as Apple has restricted developer 
access to the NFC chip, only allowing it to be used with their own \textit{Apple
    Pay} service. 

\subsection{Limitations}
The SDK does not allow for full control of all aspects of the watch. There are
some limitations to the way Apple runs third-party applications on the platform.
Most of the limitations are of course present due to user experience and battery
lifetime constraints. The watch does not allow for continuous background services, it is
dependent on having an iPhone connected to enable internet connectivity, apps can not
hinder the screen in automatically shutting off and the processing power is of
course limited in comparison to smartphones and laptops.

The main limitations affecting the development of the prototype are the lacking
ability to run background services and the automatic screen on/off.

The ability to run background services would be necessary if something like gait
recognition should function. This is not possible, and limits the continuous
tracking of an individual for identification purposes. 

If identification should rely on movement data from the accelerometer and
gyroscope, the automatic screen control is a limiting functionality. When one
moves the watch the screen very likely turns off, and the process halts. It is
possible to start workout sessions (\textit{HKWorkoutSession}) 
\cite{workoutsession} and extract the data from here, so a workaround might be 
possible, in order to extract continuous data.

% TODO: Include auto screen turn-off, continuous background services, dependency
% on phone, platform independence, limited processing power

\subsection{System Proposals}
% TODO: Mention possible setups, from findings in analysis
% TODO: Argument FOR the selected prototype, mention why the others are not
% chosen
With the sensors and limitations taken into account, three systems will be
proposed. These systems will be evaluated on their possibility of
implementation, and their usefulness.
The proposed systems will form the basis for the prototype.

\subsubsection{Voice Recognition}
This approach could utilize the built-in microphone to record and extract
features from the subjects voice. The detection could rely both on the words
being said and not. Voice recognition in general has seen an immense
advancements, due to the growing popularity and efficiency of modern machine 
learning technologies \cite{6296526}. 
This approach would therefore be both possible and convenient for users, already 
comfortable with talking to their smart devices. 
The system would need to extract features of the subjects voice, not only said
words. This is quite challenging and might also need machine learning techniques to
perform adequately. Due to the limited processing power of the Apple Watch, and
the requirements from machine learning, the recorded sound samples might need to
be sent to a central server for processing. This could result in privacy issues,
as biometric authentication data is sent over the network. It could also result
in significant latency, worsening the user experience. 

\subsubsection{Gait Recognition}
%TODO: What would this require, how does it work etc.
Using the accelerometer and gyroscope within the watch, the continuous movement
data could be used to identify the individual wearing the watch, i.e. gait
recognition. This approach could be very convenient, as it does not require any
interaction from the wearer besides wearing it, making it very pervasive.
The main problem with this, is the continuous measurements from the Apple Watch, and the
limited processing power of the watch \cite{ferrero2015a}. Since the Apple Watch
does not support background services on the watch, the continuous data retrieval
might not be possible. Furthermore gait recognition from smartwatch movement
data, has the potential of being a research project in itself. Research has been
performed on how to achieve this with smartphones \cite{ferrero2015a}, but the 
phone is normally located in pocket, whereas the watch is on the wrist, 
resulting in different movement data. As with voice recognition, gait
recognition requires machine learning techniques such as \textit{principal
    component analysis} to identify patterns and characteristics in the data,
    which would require the movement data to be sent to central servers, as the
    Apple Watch is neither powerful or efficient enough to perform these kinds
    of calculations \cite{dawson2008a}.

\subsubsection{Photoplethysmography Recognition}
%TODO: What would this require, how does it work etc.
As mentioned the built-in heart rate sensor utilizes the technology
\textit{photoplethysmography (PPG)} to detect the wearers heart rate. It is shown the
raw data from sensors like these can be used for identification
\cite{kavsaoglu2013a}. This approach like the others, require access to raw
data, but does not require it continuously as with gait recognition.
Unfortunately the recognition of subjects again requires advanced processing,
limiting the viability of such an approach. Another problem is the access to raw
PPG data from the watch. Apple only allows access to preprocessed data, i.e.\
the calculated heart rate. 
